{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this block to check GPU you've been assigned\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first time run\n",
    "!git clone https://github.com/antonioverdi/MLReproChallenge.git\n",
    "#At the moment all requirements are met by Google Colab already I believe\n",
    "import os\n",
    "os.chdir(\"MLReproChallenge\")\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsequent runs\n",
    "!git pull\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models\n",
    "### main.py Arguments\n",
    "<table>\n",
    "    <tr><th>Argument</th><th>Default</th><th>help</th></tr>\n",
    "    <tr><td>--arch, - a</td><td>str: 'resnet56'</td><td>model architecture</td></tr>\n",
    "    <tr><td>-j, --workers</td><td>int: 4</td><td>number of data loading workers</td></tr>\n",
    "    <tr><td>--epochs</td><td>int: 182</td><td>number of total epochs to run</td></tr>\n",
    "    <tr><td>--start-epoch</td><td>int: 0</td><td>manual epoch number, for restarts</td></tr>\n",
    "    <tr><td>-b, --batch-size</td><td>int: 128</td><td>mini-batch size</td></tr>\n",
    "    <tr><td>--lr, --learning-rate</td><td>float: 0.1</td><td>initial learning rate</td></tr>\n",
    "    <tr><td>--momentum</td><td>float: 0.9</td><td>momentum</td></tr>\n",
    "    <tr><td>--weight-decay, --wd</td><td>float: 2e-4</td><td>weight decay</td></tr>\n",
    "    <tr><td>--print-freq, -p</td><td>int: 50</td><td>print frequency</td></tr>\n",
    "    <tr><td>--resume</td><td>str: ' '</td><td>path to latest checkpoint</td></tr>\n",
    "    <tr><td>-e, --evaluate</td><td>bool: False</td><td>evaluate model on validation set</td></tr>\n",
    "    <tr><td>--pretrained</td><td>bool: False</td><td>use pre-trained model</td></tr>\n",
    "    <tr><td>--half</td><td>bool: False</td><td>use half-precision float(16-bit)</td></tr>\n",
    "    <tr><td>--save-dir</td><td>str: 'save_temp'</td><td>Directory used to save trained models</td></tr>\n",
    "    <tr><td>--save-every</td><td>int: 10</td><td>Save checkpoint at every specified number of epochs</td></tr>\n",
    "    <tr><td>--colab</td><td>bool: False</td><td>Set this to true when running in Google Colab</td></tr>\n",
    "    <tr><td>--snip</td><td>bool: False</td><td>Set this to true to run SNIP experiments</td></tr>\n",
    "    <tr><td>--snip_compression</td><td>float: 0.5</td><td>eg. compression of 0.25 retains 25 percent of weights</td></tr>\n",
    "   </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python main.py --colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models\n",
    "### test.py Arguments\n",
    "(currently no arguments. test.py needs to be made more colab friendly)\n",
    "<table>\n",
    "    <tr><th>Argument</th><th>Default</th><th>help</th></tr>\n",
    "    <tr><td>--arch, - a</td><td>str: 'resnet56'</td><td>model architecture</td></tr>\n",
    "   </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>SNIP experiments</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --colab --snip --arch=\"resnet56_snip\" --save-dir=\"SNIP_checkpoints\" --save-every=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import types\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((10,5))\n",
    "y = torch.ones(10, dtype=torch.long)\n",
    "y[:5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self, init_strategy=\"kaiming\"):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(5,3)\n",
    "        self.layer2 = nn.Linear(3,5)\n",
    "        if init_strategy == \"kaiming\":\n",
    "            self.apply(_kaiming_weights_init)\n",
    "        elif init_strategy == \"xavier\":\n",
    "            self.apply(_xavier_weights_init)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.layer1(x))\n",
    "        out = self.layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel(init_strategy=\"xavier\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "masks = snip_mask(model, X, y, 0.50)\n",
    "apply_snip(model, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "\t\t\t\t\t\t\t\t\t std=[0.229, 0.224, 0.225])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "\t\tdatasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "\t\t\ttransforms.RandomHorizontalFlip(),\n",
    "\t\t\ttransforms.RandomCrop(32, 4),\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t\tnormalize,\n",
    "\t\t]), download=True),\n",
    "\t\tbatch_size=16, shuffle=True,\n",
    "\t\tnum_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6454, -0.4165,  0.0000,  1.1258,  0.1893],\n",
      "        [-0.8022,  0.0000,  0.6923,  0.0000,  0.0000],\n",
      "        [ 0.1831, -0.2365, -0.6341,  0.8430,  0.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
