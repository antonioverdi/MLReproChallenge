{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first time run\n",
    "!git clone https://github.com/antonioverdi/MLReproChallenge.git\n",
    "#At the moment all requirements are met by Google Colab already I believe\n",
    "import os\n",
    "os.chdir(\"MLReproChallenge\")\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsequent runs\n",
    "!git pull\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models\n",
    "### main.py Arguments\n",
    "<table>\n",
    "    <tr><th>Argument</th><th>Default</th><th>help</th></tr>\n",
    "    <tr><td>--arch, - a</td><td>str: 'resnet56'</td><td>model architecture</td></tr>\n",
    "    <tr><td>-j, --workers</td><td>int: 4</td><td>number of data loading workers</td></tr>\n",
    "    <tr><td>--epochs</td><td>int: 182</td><td>number of total epochs to run</td></tr>\n",
    "    <tr><td>--start-epoch</td><td>int: 0</td><td>manual epoch number, for restarts</td></tr>\n",
    "    <tr><td>-b, --batch-size</td><td>int: 128</td><td>mini-batch size</td></tr>\n",
    "    <tr><td>--lr, --learning-rate</td><td>float: 0.1</td><td>initial learning rate</td></tr>\n",
    "    <tr><td>--momentum</td><td>float: 0.9</td><td>momentum</td></tr>\n",
    "    <tr><td>--weight-decay, --wd</td><td>float: 2e-4</td><td>weight decay</td></tr>\n",
    "    <tr><td>--print-freq, -p</td><td>int: 50</td><td>print frequency</td></tr>\n",
    "    <tr><td>--resume</td><td>str: ' '</td><td>path to latest checkpoint</td></tr>\n",
    "    <tr><td>-e, --evaluate</td><td>bool: False</td><td>evaluate model on validation set</td></tr>\n",
    "    <tr><td>--pretrained</td><td>bool: False</td><td>use pre-trained model</td></tr>\n",
    "    <tr><td>--half</td><td>bool: False</td><td>use half-precision float(16-bit)</td></tr>\n",
    "    <tr><td>--save-dir</td><td>str: 'save_temp'</td><td>Directory used to save trained models</td></tr>\n",
    "    <tr><td>--save-every</td><td>int: 10</td><td>Save checkpoint at every specified number of epochs</td></tr>\n",
    "    <tr><td>--colab</td><td>bool: False</td><td>Set this to true when running in Google Colab</td></tr>\n",
    "    <tr><td>--snip</td><td>bool: False</td><td>Set this to true to run SNIP experiments</td></tr>\n",
    "    <tr><td>--snip_compression</td><td>float: 0.5</td><td>eg. compression of 0.25 retains 25 percent of weights</td></tr>\n",
    "   </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python main.py --colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models\n",
    "### test.py Arguments\n",
    "(currently no arguments. test.py needs to be made more colab friendly)\n",
    "<table>\n",
    "    <tr><th>Argument</th><th>Default</th><th>help</th></tr>\n",
    "    <tr><td>--arch, - a</td><td>str: 'resnet56'</td><td>model architecture</td></tr>\n",
    "   </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>SNIP experiments</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --colab --snip --arch=\"resnet56_snip\" --save-dir=\"SNIP_checkpoints\" --save-every=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((10,5))\n",
    "y = torch.ones(10, dtype=torch.long)\n",
    "y[:5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self, init_strategy=\"kaiming\"):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(5,3)\n",
    "        self.layer2 = nn.Linear(3,5)\n",
    "        if init_strategy == \"kaiming\":\n",
    "            self.apply(_kaiming_weights_init)\n",
    "        elif init_strategy == \"xavier\":\n",
    "            self.apply(_xavier_weights_init)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.layer1(x))\n",
    "        out = self.layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _kaiming_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "        \n",
    "def _xavier_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight)\n",
    "\n",
    "def snip_forward_conv2d(self, x):\n",
    "        return F.conv2d(x, self.weight * self.weight_mask, self.bias,\n",
    "                        self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "def snip_forward_linear(self, x):\n",
    "        return F.linear(x, self.weight * self.weight_mask, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snip_mask(model, batch, labels, compression):\n",
    "    \n",
    "    \n",
    "    for layer in model.modules():\n",
    "        #create pruning masks manually\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight)) \n",
    "#             layer.weight.requires_grad = False #computing gradient of mask not weights\n",
    "\n",
    "        #monkey-patch forward methods\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
    "            \n",
    "        if isinstance(layer, nn.Linear):\n",
    "            layer.forward = types.MethodType(snip_forward_linear, layer)\n",
    "            \n",
    "    #compute gradients of weight_mask (connections)\n",
    "    model.zero_grad()\n",
    "    out = model.forward(batch)\n",
    "    loss = F.nll_loss(out, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    absolute_saliency = []\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            absolute_saliency.append(torch.abs(layer.weight_mask.grad))\n",
    "            \n",
    "    saliency_scores = torch.cat([torch.flatten(x) for x in absolute_saliency])\n",
    "    denominator = torch.sum(saliency_scores)\n",
    "    saliency_scores.div_(denominator)\n",
    "    \n",
    "    kappa = int(len(saliency_scores) * compression)\n",
    "    sorted_scores, indices = torch.topk(saliency_scores, kappa, sorted=True)\n",
    "    threshold = sorted_scores[-1]\n",
    "    \n",
    "    connection_masks = []\n",
    "    for c in absolute_saliency:\n",
    "        connection_masks.append(((c / denominator) >= threshold).float())\n",
    "    \n",
    "    return connection_masks\n",
    "\n",
    "def apply_snip(model, connection_masks):\n",
    "    prunable_layers = filter(lambda layer: isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear), model.modules())\n",
    "\n",
    "    for layer, mask in zip(prunable_layers, connection_masks):\n",
    "#         assert (layer.weight.shape == keep_mask.shape)\n",
    "\n",
    "        def hook_factory(keep_mask):\n",
    "            \"\"\"\n",
    "            The hook function can't be defined directly here because of Python's\n",
    "            late binding which would result in all hooks getting the very last\n",
    "            mask! Getting it through another function forces early binding.\n",
    "            source: https://github.com/mil-ad/snip/blob/master/train.py\n",
    "            \"\"\"\n",
    "\n",
    "            def hook(grads):\n",
    "                return grads * keep_mask\n",
    "\n",
    "            return hook\n",
    "\n",
    "        # Set the masked weights to zero (biases are ignored)\n",
    "        layer.weight.data[mask == 0.] = 0.\n",
    "        # Make sure their gradients remain zero. Register_hook gets called whenever a gradient is collected\n",
    "        layer.weight.register_hook(hook_factory(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel(init_strategy=\"xavier\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "masks = snip_mask(model, X, y, 0.50)\n",
    "apply_snip(model, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dfcd88c8f871>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtestlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "testlist = [5, 6, 7]\n",
    "print(testlist.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
