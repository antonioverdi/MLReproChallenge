{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first time run\n",
    "!git clone https://github.com/antonioverdi/MLReproChallenge.git\n",
    "#At the moment all requirements are met by Google Colab already I believe\n",
    "import os\n",
    "os.chdir(\"MLReprochallenge\")\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsequent runs\n",
    "!git pull\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models\n",
    "### Main.py Arguments\n",
    "<table>\n",
    "    <tr><th>Argument</th><th>Default</th><th>help</th></tr>\n",
    "    <tr><td>--arch, - a</td><td>str: 'resnet56'</td><td>model architecture</td></tr>\n",
    "    <tr><td>-j, --workers</td><td>int: 4</td><td>number of data loading workers</td></tr>\n",
    "    <tr><td>--epochs</td><td>int: 182</td><td>number of total epochs to run</td></tr>\n",
    "    <tr><td>--start-epoch</td><td>int: 0</td><td>manual epoch number, for restarts</td></tr>\n",
    "    <tr><td>-b, --batch-size</td><td>int: 128</td><td>mini-batch size</td></tr>\n",
    "    <tr><td>--lr, --learning-rate</td><td>float: 0.1</td><td>initial learning rate</td></tr>\n",
    "    <tr><td>--momentum</td><td>float: 0.9</td><td>momentum</td></tr>\n",
    "    <tr><td>--weight-decay, --wd</td><td>float: 2e-4</td><td>weight decay</td></tr>\n",
    "    <tr><td>--print-freq, -p</td><td>int: 50</td><td>print frequency</td></tr>\n",
    "    <tr><td>--resume</td><td>str: ' '</td><td>path to latest checkpoint</td></tr>\n",
    "    <tr><td>-e, --evaluate</td><td>bool: False</td><td>evaluate model on validation set</td></tr>\n",
    "    <tr><td>--pretrained</td><td>bool: False</td><td>use pre-trained model</td></tr>\n",
    "    <tr><td>--half</td><td>bool: False</td><td>use half-precision float(16-bit)</td></tr>\n",
    "    <tr><td>--save-dir</td><td>str: 'save_temp'</td><td>Directory used to save trained models</td></tr>\n",
    "    <tr><td>--save-every</td><td>int: 10</td><td>Save checkpoint at every specified number of epochs</td></tr>\n",
    "    <tr><td>--colab</td><td>bool: False</td><td>Set this to true when running in Google Colab</td></tr>\n",
    "   </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python main.py --colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((10,5))\n",
    "y = torch.ones(10, dtype=torch.long)\n",
    "y[:5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self, init_strategy=\"kaiming\"):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(5,3)\n",
    "        self.layer2 = nn.Linear(3,5)\n",
    "        if init_strategy == \"kaiming\":\n",
    "            self.apply(_kaiming_weights_init)\n",
    "        elif init_strategy == \"xavier\":\n",
    "            self.apply(_xavier_weights_init)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.layer1(x))\n",
    "        out = self.layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _kaiming_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "        \n",
    "def _xavier_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight)\n",
    "\n",
    "def snip_forward_conv2d(self, x):\n",
    "        return F.conv2d(x, self.weight * self.weight_mask, self.bias,\n",
    "                        self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "def snip_forward_linear(self, x):\n",
    "        return F.linear(x, self.weight * self.weight_mask, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snip_mask(model, batch, labels, compression):\n",
    "    \n",
    "    \n",
    "    for layer in model.modules():\n",
    "        #create pruning masks manually\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight)) \n",
    "#             layer.weight.requires_grad = False #computing gradient of mask not weights\n",
    "\n",
    "        #monkey-patch forward methods\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
    "            \n",
    "        if isinstance(layer, nn.Linear):\n",
    "            layer.forward = types.MethodType(snip_forward_linear, layer)\n",
    "            \n",
    "    #compute gradients of weight_mask (connections)\n",
    "    model.zero_grad()\n",
    "    out = model.forward(batch)\n",
    "    loss = F.nll_loss(out, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    absolute_saliency = []\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            absolute_saliency.append(torch.abs(layer.weight_mask.grad))\n",
    "            \n",
    "    saliency_scores = torch.cat([torch.flatten(x) for x in absolute_saliency])\n",
    "    denominator = torch.sum(saliency_scores)\n",
    "    saliency_scores.div_(denominator)\n",
    "    \n",
    "    kappa = int(len(saliency_scores) * compression)\n",
    "    sorted_scores, indices = torch.topk(saliency_scores, kappa, sorted=True)\n",
    "    threshold = sorted_scores[-1]\n",
    "    \n",
    "    connection_masks = []\n",
    "    for c in absolute_saliency:\n",
    "        connection_masks.append(((c / denominator) >= threshold).float())\n",
    "    \n",
    "    return connection_masks\n",
    "\n",
    "def apply_snip(model, connection_masks):\n",
    "    prunable_layers = filter(lambda layer: isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear), model.modules())\n",
    "\n",
    "    for layer, mask in zip(prunable_layers, connection_masks):\n",
    "#         assert (layer.weight.shape == keep_mask.shape)\n",
    "\n",
    "        def hook_factory(keep_mask):\n",
    "            \"\"\"\n",
    "            The hook function can't be defined directly here because of Python's\n",
    "            late binding which would result in all hooks getting the very last\n",
    "            mask! Getting it through another function forces early binding.\n",
    "            source: https://github.com/mil-ad/snip/blob/master/train.py\n",
    "            \"\"\"\n",
    "\n",
    "            def hook(grads):\n",
    "                return grads * keep_mask\n",
    "\n",
    "            return hook\n",
    "\n",
    "        # Set the masked weights to zero (biases are ignored)\n",
    "        layer.weight.data[mask == 0.] = 0.\n",
    "        # Make sure their gradients remain zero. Register_hook gets called whenever a gradient is collected\n",
    "        layer.weight.register_hook(hook_factory(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel(init_strategy=\"xavier\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "masks = snip_mask(model, X, y, 0.50)\n",
    "apply_snip(model, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2113, -0.6545, -0.6346,  0.2245,  0.0700],\n",
      "        [-0.1113, -0.5254, -0.5355,  0.2784,  0.0494],\n",
      "        [-0.1040, -0.6149, -0.7418,  0.0143, -0.0199],\n",
      "        [-0.1213, -0.5356, -0.5395,  0.2805,  0.0533],\n",
      "        [-0.1682, -0.6183, -0.6340,  0.1948,  0.0477],\n",
      "        [-0.6083, -1.2680, -1.2461, -0.2632,  0.0826],\n",
      "        [ 0.0513, -0.3832, -0.5205,  0.1825, -0.0305],\n",
      "        [ 0.1009, -0.3099, -0.4514,  0.2343, -0.0344],\n",
      "        [ 0.1009, -0.3099, -0.4514,  0.2343, -0.0344],\n",
      "        [-0.0264, -0.4392, -0.5018,  0.2607,  0.0159]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2113, -0.6545, -0.6346,  0.2245,  0.0700],\n",
      "        [-0.1113, -0.5254, -0.5355,  0.2784,  0.0494],\n",
      "        [-0.1040, -0.6149, -0.7418,  0.0143, -0.0199],\n",
      "        [-0.1213, -0.5356, -0.5395,  0.2805,  0.0533],\n",
      "        [-0.1682, -0.6183, -0.6340,  0.1948,  0.0477],\n",
      "        [-0.6083, -1.2680, -1.2461, -0.2632,  0.0826],\n",
      "        [ 0.0513, -0.3832, -0.5205,  0.1825, -0.0305],\n",
      "        [ 0.1009, -0.3099, -0.4514,  0.2343, -0.0344],\n",
      "        [ 0.1009, -0.3099, -0.4514,  0.2343, -0.0344],\n",
      "        [-0.0264, -0.4392, -0.5018,  0.2607,  0.0159]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "model1 = TestModel(init_strategy=\"xavier\")\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=0.0001)\n",
    "output = model1.forward(X)\n",
    "print(output)\n",
    "masks = snip_mask(model1, X, y, 0.5)\n",
    "apply_snip(model1, masks)\n",
    "output = model1.forward(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000, -0.1337,  0.3056,  0.2123,  0.4977],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.5045],\n",
      "        [ 0.5046,  0.3541,  0.0000,  0.3363,  1.2411]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3632,  0.1242, -0.4400], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.9418,  0.3743, -0.1923],\n",
      "        [ 0.2898, -0.5059, -0.1182],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3812,  0.2165,  0.3906,  0.4295, -0.1825], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.parameters():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8507, 0.8685, 0.7784, 0.6547, 0.7529],\n",
      "        [0.0561, 0.8708, 0.2868, 0.2654, 0.6038],\n",
      "        [0.0824, 0.7327, 0.5353, 0.8400, 0.6228],\n",
      "        [0.2959, 0.5033, 0.7964, 0.8578, 0.9757],\n",
      "        [0.0246, 0.0190, 0.2140, 0.9614, 0.1417],\n",
      "        [0.8252, 0.5460, 0.0270, 0.6644, 0.5456],\n",
      "        [0.5410, 0.0719, 0.3772, 0.5851, 0.8779],\n",
      "        [0.2785, 0.2152, 0.5592, 0.9359, 0.2258],\n",
      "        [0.2346, 0.0415, 0.2520, 0.1155, 0.2644],\n",
      "        [0.1498, 0.0111, 0.7135, 0.9518, 0.1588]])\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
